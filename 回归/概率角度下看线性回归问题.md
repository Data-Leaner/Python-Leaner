- 数据集

  $$D = \{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{n},y_{n})\}$$

  $x_{i} \in \mathbb{R}^{p}$, $x_{i}$是$p$维列向量

  $y_{i} \in \mathbb{R}$，$i=1,2,...,n$

  $$X=\begin{bmatrix}x_{1} & x_{2} & ... x_{n}\end{bmatrix}^{T} = \begin{bmatrix} x_{1}^{T} \\ x_{2}^{T} \\ ... \\ x_{n}^{T} \end{bmatrix} = \begin{bmatrix} x_{11} & x_{12} & ... & x_{1p} \\ x_{21} & x_{22} & ... & x_{2p} \\ ... & ... & ... & ... \\ x_{n1} & x_{n2} & ... & x_{np} \end{bmatrix}_{n \times p}$$

  $$Y = \begin{bmatrix}y_{1} \\ y_{2} \\ ... \\ y_{n}\end{bmatrix}_{n \times 1}$$

- 拟合函数

  $$W = \begin{bmatrix}w_{1} \\ w_{2} \\ ... \\ w_{p}\end{bmatrix}_{p \times 1}$$

  $$f(w) = W^{T}x + b$$
  $b$可以看做$w_{0}$，那么拟合函数也可以用$f(w) = W^{T}x$来表示

- 最小二乘法

  **$x_{i}$是一个$p$维的向量**

  $$L(W) = \sum\limits_{i=1}^{N}||W^{T}x_{i} - y_{i}||^{2}$$

## 概率角度解释线性回归
$\epsilon$服从正态分布
$$\epsilon \sim N(0, \sigma^{2}) $$

$$y = f(w) + \epsilon$$

$$f(w) = W^{T}x$$

$$y = W^{T}x + \epsilon$$

$$y|x_{i};w \sim N(W^{T}x, \sigma^{2})$$

- MLE
log似然
$$\mathbb{L}(w) = logP(Y|X;W)$$

$$\Rightarrow \log\prod\limits_{i=1}^{n}P(y_{i}|x_{i};W)$$

$$\Rightarrow \sum\limits_{i=1}^{n}logP(y_{i} | x_{i}; W) $$

$$\Rightarrow \sum\limits_{i=1}^{n}log\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_{i} - X^{T}W)^2}{2\sigma^{2}}}$$

$$\Rightarrow \sum\limits_{i=1}^{n}log\frac{1}{\sqrt{2\pi}\sigma} + \sum\limits_{i=1}^{n}e^{-\frac{(y_{i} - X^{T}W)^2}{2\sigma^{2}}}$$

$$\Rightarrow \sum\limits_{i=1}^{n}log\frac{1}{\sqrt{2\pi}\sigma} + \sum\limits_{i=1}^{n}-\frac{(y_{i} - X^{T}W)^2}{2\sigma^{2}}$$

$$\widehat W = argmax\mathbb{L}(w)$$

$$\widehat W = argmax -\frac{(y_{i} - X^{T}W)^2}{2\sigma^{2}}$$

$$\widehat W = argmin \frac{(y_{i} - X^{T}W)^2}{2\sigma^{2}}$$

**结论**：最小二乘隐含噪声服从正态分布假设
