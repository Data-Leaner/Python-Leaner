- 单特征
> 一元线性回归

- 多特征
> 多元线性回归

**当$Y$值的影响因素不是唯一的时候，采用多元线性回归**
$h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1}+\theta_{2}x_{2} + ... + \theta_{n}x_{n}$

- Hypothesis
$h_{\theta}(x) = \theta^{T} = \theta_{0} + \theta_{1}x_{1}+\theta_{2}x_{2} + ... + \theta_{n}x_{n}$

- Parameter
$\theta_{0}$, $\theta_{1}$,$\theta_{2}$,...,$\theta_{n}$

- Cost function
$J(\theta_{0}, \theta_{1},...,\theta_{n})=\frac{1}{2m}\sum\limits_{i=1}^{m}(h_{\theta}(x_{i}) - y_{i})^2$

- Gradient Descent
$\theta_{j} := \theta_{j} - \alpha\frac{\partial}{\partial\theta_{j}}J(\theta_{0}, \theta_{1},\theta_{2},...,\theta_{n})$

$\Rightarrow \theta_{0} := \theta_{0} - \alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x_{i}) - y_{i})$

$\Rightarrow \theta_{1} := \theta_{1} - \alpha \frac{x_{1}}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x_{i}) - y_{i})$

$\Rightarrow \theta_{2} := \theta_{2} - \alpha \frac{x_{2}}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x_{i}) - y_{i})$

$\Rightarrow ...$

```python

```
